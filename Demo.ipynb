{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016bb4cc",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "#### This script performs feature extraction and data processing on audio files stored in a directory. In detail:\n",
    "\n",
    "1) Calls the function \"directory_feature_extraction\" from the MidTermFeatures module of the pyAudioAnalysis library, passing the path to the audio files directory, and parameters for the extraction process (1 audio file per 1 sec with 0.1 overlap, and 0.1 offset).\n",
    "\n",
    "2) Stores the extracted features and corresponding audio file names in the variables \"mid_term_features\", \"wav_file_list\", and \"mid_feature_names\" respectively.\n",
    "\n",
    "3) Normalizes the extracted features by calculating the mean and standard deviation and then subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "4) Creates a pandas dataframe from the normalized features and sets the columns names to the mid_feature_names and exports the dataframe to a CSV file with a name of your choice \"name_of_your_choice.csv\". \n",
    "\n",
    "Function mid_feature_extraction() from the MidTermFeatures.py file extracts a number of statistcs (e.g. mean and standard deviation) short-term feature sequences.The total number of short-term features implemented in pyAudioAnalysis is 34. In addition, the delta features are optionally computed (they are by default enabled, but can be disabled by setting the deltas argument in feature_extraction() to false). So, the total number of short-term features, including the deltas is 64.\n",
    "\n",
    "A table of the exact short term features can be found in:\n",
    "\n",
    "https://github.com/tyiannak/pyAudioAnalysis/wiki/3.-Feature-Extraction\n",
    "\n",
    "In the extracted features, beat extraction is included.Tempo induction is a rather important task in music information retrieval. This library provides a baseline method for estimating the beats per minute (BPM) rate of a music signal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47278f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing file 1 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk10.wav\n",
      "Analyzing file 2 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk100.wav\n",
      "Analyzing file 3 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk101.wav\n",
      "Analyzing file 4 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk102.wav\n",
      "Analyzing file 5 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk103.wav\n",
      "Analyzing file 6 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk104.wav\n",
      "Analyzing file 7 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk105.wav\n",
      "Analyzing file 8 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk106.wav\n",
      "Analyzing file 9 of 250: C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing\\chunk107.wav\n",
      "etc.",
      "Feature extraction complexity ratio: 24.8 x realtime\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "import numpy as np\n",
    "\n",
    "# Input is the file where the audios are located, used to train different composers and categories(Mozart-Piano,Bethoveen-Symphonies etc)\n",
    "mid_term_features, wav_file_list, mid_feature_names = mtf.directory_feature_extraction('C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Bethoveen/Symphonies/Testing', 1, 1, 0.1, 0.1)\n",
    "m = mid_term_features.mean(axis=0)\n",
    "s = np.std(mid_term_features, axis = 0)\n",
    "mid_term_features_2 = (mid_term_features - m) / s\n",
    "\n",
    "# dataFrame from the features and file names\n",
    "df = pd.DataFrame(mid_term_features_2, columns=mid_feature_names)\n",
    "\n",
    "\n",
    "# dataFrame to CSV \n",
    "df.to_csv('Bethoveen_symphonies_testing2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602ca72",
   "metadata": {},
   "source": [
    "## Merging the produced dataframes and adding labels to them\n",
    "\n",
    "1) Adds a new column named \"label\" to each of the dataframes and assigns each a unique label.\n",
    "2) Merges the multiple dataframes into one dataframe using \"pd.concat\" function.\n",
    "3) Saves the merged dataframe to a new CSV file.\n",
    "\n",
    "The code can be used to create the exact csv file you want. For example if you want to create a Bethoveen_piano_testing.csv file you can use: \n",
    "\n",
    "`df8 = pd.read_csv('Bethoveen_piano_testing.csv')`\n",
    "\n",
    "`df8[\"label\"] = 4`\n",
    "\n",
    "`merged_df= pd.concat([df8])`\n",
    "\n",
    "`merged_df.to_csv(\"Bethoveen_piano_testing.csv\", index=False)`\n",
    "\n",
    "The code bellow creates a \"piano.csv\" for training and a \"piano_testing.csv\" for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV\n",
    "df1 = pd.read_csv(\"Schubert_piano_training.csv\")\n",
    "df2 = pd.read_csv(\"Schumann_piano_training.csv\")\n",
    "df3 = pd.read_csv(\"Mozart_piano_training.csv\")\n",
    "df4 = pd.read_csv(\"Bethoveen_piano_training.csv\")\n",
    "\n",
    "# New column with the labels\n",
    "df1[\"label\"] = 1\n",
    "df2[\"label\"] = 2\n",
    "df3[\"label\"] = 3\n",
    "df4[\"label\"] = 4\n",
    "\n",
    "# Merge dataframe\n",
    "merged_df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "# Save merged to CSV \n",
    "merged_df.to_csv(\"Piano.csv\", index=False)\n",
    "\n",
    "# Same for \"testing\" \n",
    "df5 = pd.read_csv('Schubert_piano_testing.csv')\n",
    "df6 = pd.read_csv('Schumann_piano_testing.csv')\n",
    "df7 = pd.read_csv('Mozart_piano_testing.csv')\n",
    "df8 = pd.read_csv('Bethoveen_piano_testing.csv')\n",
    "\n",
    "df5[\"label\"] = 1\n",
    "df6[\"label\"] = 2\n",
    "df7[\"label\"] = 3\n",
    "df8[\"label\"] = 4\n",
    "\n",
    "merged_df_2 = pd.concat([df5,df6,df7,df8])\n",
    "merged_df_2.to_csv(\"Piano_testing.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d37885",
   "metadata": {},
   "source": [
    "## Used for training and input of testing\n",
    "\n",
    "This code performs the following tasks:\n",
    "\n",
    "1) Loads the training data and test data.\n",
    "2) Selects the top N features using a classifier of your choise.\n",
    "3) Drops the label columns from the training and test data to use as the features and target.\n",
    "4) Fits a classifier using one of several options (SVM, Logistic Regression, Random Forest, KNN, Neural Network, or Naive Bayes) on the training data and selected features.\n",
    "5) Performs 10-fold shuffle split cross-validation on the training data to evaluate the performance of the classifier.\n",
    "6) Prints the mean f1 score the sigma f1 and the confidence of the 10-fold shuffle split cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce39d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['energy_entropy_mean', 'spectral_centroid_mean', 'spectral_spread_mean',\n",
      "       'spectral_entropy_mean', 'mfcc_1_mean', 'mfcc_2_mean',\n",
      "       'delta mfcc_8_std', 'delta mfcc_10_std', 'delta mfcc_11_std', 'ratio'],\n",
      "      dtype='object')\n",
      "mean f1: 0.656, sigma f1: 0.012, 95% conf: 0.631 - 0.681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, chi2, mutual_info_regression, f_classif,f_regression, SelectFwe\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Read training data\n",
    "train_data = pd.read_csv(\"Piano.csv\")\n",
    "\n",
    "# Define the features and target\n",
    "X = train_data.drop(\"label\", axis=1)\n",
    "y = train_data[\"label\"]\n",
    "\n",
    "# SelectKBest to select the top N features\n",
    "selector = RFE(SVC(kernel=\"linear\"), n_features_to_select=10) # A different selector that can be used\n",
    "#selector = SelectKBest(mutual_info_classif, k=20)\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Print names of features\n",
    "print(X.columns[selected_features])\n",
    "\n",
    "# test data\n",
    "test_data = pd.read_csv(\"Piano_testing.csv\")\n",
    "\n",
    "# Drop labels in x, y are test labels\n",
    "X_test = test_data.drop(\"label\", axis=1)\n",
    "Y_test = test_data[\"label\"]\n",
    "\n",
    "#Select only the features that were selected in the previous step for test and trainign\n",
    "selected_features_name = X.columns[selected_features]\n",
    "X = X[selected_features_name]\n",
    "X_test = X_test[selected_features_name]\n",
    "\n",
    "# Train a classifier on the training data\n",
    "#clf = RandomForestClassifier()\n",
    "#clf = LogisticRegression()\n",
    "#clf = SVC()\n",
    "#clf = KNeighborsClassifier(n_neighbors=6)\n",
    "clf = MLPClassifier(max_iter=20000)\n",
    "#clf = GaussianNB()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "#K-fold validation\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n",
    "p1 = cross_val_score(clf, X, y, cv=cv, scoring='f1_macro')\n",
    "\n",
    "\n",
    "print(f\"mean f1: {p1.mean():.3f}, sigma f1: {p1.std():.3f}, 95% conf: {p1.mean()-2*p1.std():.3f} - {p1.mean()+2*p1.std():.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203bb18",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "1) Predicts the class labels for test data using the chosen classifier of the previous step.\n",
    "2) Calculates the accuracy of the predicted labels.\n",
    "3) Calculates the F1 score of the model using the true labels of the test data and the predicted labels.\n",
    "4) Prints the F1 score and accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e637bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model:  0.4038741857700229\n",
      "Accuracy of the model:  0.407\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Y_pred= clf.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred, average='macro')\n",
    "print(\"F1 score of the model: \", f1)\n",
    "print(\"Accuracy of the model: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
