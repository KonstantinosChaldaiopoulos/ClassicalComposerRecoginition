{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c281db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852221f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyAudioAnalysis import MidTermFeatures as mtf\n",
    "import numpy as np\n",
    "\n",
    "# Input is the file where the audios are located, used to train different composers and categories(Mozart-Piano,Bethoveen-Symphonies etc)\n",
    "mid_term_features, wav_file_list, mid_feature_names = mtf.directory_feature_extraction('C:/Users/user/OneDrive/Υπολογιστής/Εργασία machine learning dataset/Mozart/Piano Pieces/Testing', 1, 1, 0.1, 0.1)\n",
    "m = mid_term_features.mean(axis=0)\n",
    "s = np.std(mid_term_features, axis = 0)\n",
    "mid_term_features_2 = (mid_term_features - m) / s\n",
    "\n",
    "# dataFrame from the features and file names\n",
    "df = pd.DataFrame(mid_term_features_2, columns=mid_feature_names)\n",
    "\n",
    "\n",
    "# dataFrame to CSV \n",
    "df.to_csv('Mozart_piano_testing', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672df99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used for merging the produced dataframe and adding labels to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0c98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV\n",
    "df1 = pd.read_csv(\"Schubert_piano_training\")\n",
    "df2 = pd.read_csv(\"Schumann_piano_training\")\n",
    "df3 = pd.read_csv(\"Mozart_piano_training\")\n",
    "df4 = pd.read_csv(\"Bethoveen_piano_training\")\n",
    "\n",
    "# New column with the labels\n",
    "df1[\"label\"] = 1\n",
    "df2[\"label\"] = 2\n",
    "df3[\"label\"] = 3\n",
    "df4[\"label\"] = 4\n",
    "\n",
    "# Merge datafram\n",
    "merged_df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "# Save merged to CSV \n",
    "merged_df.to_csv(\"Piano\", index=False)\n",
    "\n",
    "# Same for \"testing\" \n",
    "df5 = pd.read_csv('Schubert_piano_testing')\n",
    "df6 = pd.read_csv('Schumann_piano_testing')\n",
    "df7 = pd.read_csv('Mozart_piano_testing')\n",
    "df8 = pd.read_csv('Bethoveen_piano_testing')\n",
    "\n",
    "df5[\"label\"] = 1\n",
    "df6[\"label\"] = 2\n",
    "df7[\"label\"] = 3\n",
    "df8[\"label\"] = 4\n",
    "\n",
    "merged_df_2 = pd.concat([df5, df6, df7, df8])\n",
    "merged_df_2.to_csv(\"Piano_testing\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used for training and input of testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce39d3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['zcr_mean', 'energy_mean', 'energy_entropy_mean',\n",
      "       'spectral_centroid_mean', 'spectral_spread_mean',\n",
      "       'spectral_entropy_mean', 'spectral_flux_mean', 'spectral_rolloff_mean',\n",
      "       'mfcc_1_mean', 'mfcc_2_mean',\n",
      "       ...\n",
      "       'delta chroma_6_std', 'delta chroma_7_std', 'delta chroma_8_std',\n",
      "       'delta chroma_9_std', 'delta chroma_10_std', 'delta chroma_11_std',\n",
      "       'delta chroma_12_std', 'delta chroma_std_std', 'bpm', 'ratio'],\n",
      "      dtype='object', length=138)\n",
      "mean f1: 0.774, sigma f1: 0.013, 95% conf: 0.748 - 0.801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# Read training data\n",
    "train_data = pd.read_csv(\"Piano\")\n",
    "\n",
    "# Define the features and target\n",
    "X = train_data.drop(\"label\", axis=1)\n",
    "y = train_data[\"label\"]\n",
    "\n",
    "# SelectKBest to select the top N features\n",
    "selector = SelectKBest(mutual_info_classif, k=138)\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = selector.get_support(indices=True)\n",
    "\n",
    "# Print names of features\n",
    "print(X.columns[selected_features])\n",
    "\n",
    "# test data\n",
    "test_data = pd.read_csv(\"Piano_testing\")\n",
    "\n",
    "# Drop labels in x, y are test labels\n",
    "X_test = test_data.drop(\"label\", axis=1)\n",
    "Y_test = test_data[\"label\"]\n",
    "\n",
    "# Select only the features that were selected in the previous step for test and trainign\n",
    "selected_features_name = X.columns[selected_features]\n",
    "X = X[selected_features_name]\n",
    "X_test = X_test[selected_features_name]\n",
    "\n",
    "# Train a classifier on the training data\n",
    "#clf = RandomForestClassifier()\n",
    "#clf = LogisticRegression()\n",
    "clf = SVC()\n",
    "#clf = KNeighborsClassifier(n_neighbors=4)\n",
    "#clf = MLPClassifier(max_iter=5000)\n",
    "#clf = GaussianNB()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "#K-fold validation\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n",
    "p1 = cross_val_score(clf, X, y, cv=cv, scoring='f1_macro')\n",
    "\n",
    "\n",
    "print(f\"mean f1: {p1.mean():.3f}, sigma f1: {p1.std():.3f}, 95% conf: {p1.mean()-2*p1.std():.3f} - {p1.mean()+2*p1.std():.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbb9884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e637bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  0.387\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Y_pred= clf.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy of the model: \", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
